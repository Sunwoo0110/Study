# 📚 Incident Handling & Performance Diagnosis

---

## 1. 주제/키워드
- 현업에서 문제(에러/성능 이슈)가 발생했을 때 어떻게 파악하고 해결할까 (｡･ω･｡)?

---

## 📑 목차

- [📚 Incident Handling \& Performance Diagnosis](#-incident-handling--performance-diagnosis)
  - [1. 주제/키워드](#1-주제키워드)
  - [📑 목차](#-목차)
  - [2. 핵심 요약 (Summary)](#2-핵심-요약-summary)
    - [문제 파악 프로세스](#문제-파악-프로세스)
      - [활용 도구](#활용-도구)
      - [주의할 점](#주의할-점)
    - [토스 해외주식 서비스 안정화](#토스-해외주식-서비스-안정화)
      - [문제 상황](#문제-상황)
      - [해결 방안](#해결-방안)
      - [정리](#정리)
    - [토스 프로파일러로 시스템 성능 향상시키기](#토스-프로파일러로-시스템-성능-향상시키기)
      - [주요 툴](#주요-툴)
      - [문제 사례 및 해결 방법](#문제-사례-및-해결-방법)
      - [MSA 환경에서 성능 병목 탐지](#msa-환경에서-성능-병목-탐지)
      - [JVM 힙 메모리 이슈](#jvm-힙-메모리-이슈)
      - [네이티브 메모리 증가](#네이티브-메모리-증가)
      - [CPU 사용률 과다](#cpu-사용률-과다)
      - [Spring Cloud Gateway 라우팅 성능 저하](#spring-cloud-gateway-라우팅-성능-저하)
      - [Redis 응답 지연](#redis-응답-지연)
      - [Istio(Service Mesh) 환경에서의 연결 비용](#istioservice-mesh-환경에서의-연결-비용)
      - [외부 라이브러리 문제](#외부-라이브러리-문제)
      - [정리](#정리-1)
    - [토스 실시간 시세 데이터 안전하고 빠르게 처리하기](#토스-실시간-시세-데이터-안전하고-빠르게-처리하기)
    - [해결 방법](#해결-방법)
    - [이중화 및 Failover 구조](#이중화-및-failover-구조)
    - [메시지 브로커 도입](#메시지-브로커-도입)
    - [Consumer 성능 최적화](#consumer-성능-최적화)
    - [멀티스레딩/이벤트 루프 튜닝](#멀티스레딩이벤트-루프-튜닝)
    - [성과](#성과)
    - [정리](#정리-2)
  - [3. 느낀 점 (Insights)](#3-느낀-점-insights)
  - [4. 참고/추가 자료 (References)](#4-참고추가-자료-references)
  - [5. 내일/다음에 볼 것 (Next-Steps)](#5-내일다음에-볼-것-next-steps)

---

## 2. 핵심 요약 (Summary)

### 문제 파악 프로세스
- 문제가 발생했을 때, 어떤 식으로 원인을 찾아야할까?
- 문제 발견 -> 범위 축소 -> 원인 파악 -> 검증

- 사용자가 **불편함을 겪고 있는 부분**을 기반으로 확인
  - API 응답 지연, Latency, 에러율 확인
- 시스템 레벨 모니터링
  - CPU, Memory, Disk I/O, 네트워크 상태
- 범위 축소 (Divide & Conquer)
  - 요청 구간별(start/end 로그 등을 활용)로 느린 지점 탐색
- 원인 가설 설정
  - DB 인덱스 누락, 캐시 미스, Deadlock, 네트워크 지연 등
- 재현 & 검증
  - **부하 테스트**(k6, JMeter)로 동일 현상 재현 후 검증
- 심화 분석
  - APM(NewRelic, Datadog, Pinpoint), 프로파일러(JConsole, VisualVM)로 상세 추적


#### 활용 도구
- 로그/지표: Latency, Error rate
- APM: Pinpoint, Datadog, NewRelic
- 모니터링: Prometheus + Grafana
- 부하 테스트: JMeter, k6, Locust
- 프로파일러: JVM, Python(cProfile)


#### 주의할 점
- 지표, 측정 값 기반 접근
- 처음부터 전부 최적화하기 보단,  **가장 큰 병목부터 해결**
- 인프라(OS, 네트워크), 애플리케이션(DB, 코드) 둘 다 확인해보자

--- 

### 토스 해외주식 서비스 안정화

#### 문제 상황
- 정규장 시작(22:30)에 트래픽이 평시 대비 20배 폭증
- 초기 대비 사용자/주문 30배 성장 -> 브로커 응답 지연 -> 누적 대기/장애 발생

#### 해결 방안
1. **트래픽 제어**
   - 예약 주문(100만 건)을 **배치로 전송**
   - Resilience4j RateLimiter로 브로커 TPS 제어 (동적 조절 가능)

2. **이상 탐지 & Failover 자동화**
   - Grafana/Kibana 기반 모니터링 + Alert Rule
   - 이상 발생 -> Kafka 이벤트 발행 -> 구독 시스템 자동 대응
   - Critical 시 브로커 Failover 자동 실행 + Slack 알림

3. **데이터 관리 최적화**
   - Oracle 파티션(날짜 단위) + MongoDB(계좌 단위 샤딩) 혼합 전략
   - 과거 데이터: Hadoop Impala -> MongoDB 이관
   - 신규 데이터: Kafka 기반 실시간 동기화

#### 정리
- 문제의 본질을 빠르게 파악하고 검증된 도구(Resilience4j, Kafka, Grafana 등)로 **안정화**
- 오버엔지니어링 X -> 절약한 시간은 핵심 기능 개발에 집중하기

---


### 토스 프로파일러로 시스템 성능 향상시키기

#### 주요 툴
- 분산 트랜잭션 분석: Pinpoint
- JVM 힙 분석: Heap Dump, MAT(Object Query Language)
- 네이티브 메모리 분석: JEmalloc
- CPU & 메모리 프로파일링: Sync Profiler, Perf
- 시스템 콜 분석: strace, perf trace
- Reverse Engineering: Binary Ninja
- Service Mesh / Network 성능 분석: Istio, eBPF, Unix Domain Socket

#### 문제 사례 및 해결 방법

#### MSA 환경에서 성능 병목 탐지
- 문제: 배포가 지연되고, Spring Cloud Config Server 응답이 비정상적으로 느려짐
- 분석: Pinpoint로 **분산 트랜잭션 추적** -> 특정 메소드가 암호화 필드 복호화 반복 -> 이때, 복호화를 싱글 스레드로 처리함 -> 데이터가 많을수록 시간이 매우 오래 걸림
- 해결: 싱글 스레드 처리 -> **멀티 스레드** -> 응답속도 단축


#### JVM 힙 메모리 이슈
- 문제: Old Generation 메모리가 급격히 증가, GC time 상승
- 분석: Heap Dump + MAT -> 특정 옵션으로 불필요 객체 지속 생성 확인
- 해결: 불필요 옵션 제거/수정 -> 메모리 안정화


#### 네이티브 메모리 증가
- 문제: Heap 크기 제한 내인데도 OOM 발생 (네이티브 메모리 증가)
- 분석: JEmalloc + LD Debug -> 특정 객체 해제 누락 발견
- 해결: 코드 수정 후 재분석 -> 문제 해결, 메모리 사용량 정상화

#### CPU 사용률 과다
- 문제: Elasticsearch 사용 중 CPU 부하 급증
- 분석: Sync Profiler로 Flame Graph 분석 -> 날짜 파싱(ISO format)에서 성능 저하 확인
- 해결: Epoch millis 기반 파싱으로 교체 -> CPU 사용량 대폭 감소

#### Spring Cloud Gateway 라우팅 성능 저하
- 문제: 동일 요청 시에도 라우트 개수만큼 매번 주소 파싱
- 해결: 라우트 캐싱 적용 -> 중복 연산 제거, 응답 성능 향상

#### Redis 응답 지연
- 문제: Redis 응답이 지연됨, 네트워크 문제인지 애플리케이션 문제인지 불명확
- 분석: strace 이용 -> `read()` syscall에서 240ms 지연 확인
- 해결: OS 커널 업그레이드 후 개선 -> 커널 버전이 성능에 큰 영향 있음 확인(신기하구만)

#### Istio(Service Mesh) 환경에서의 연결 비용
- 문제: 트래픽 급증 시, 클라이언트-프록시-서버 간 3중 연결로 비용 증가
- 해결: HTTP/2 적용 + eBPF/Unix Domain Socket 실험 -> 연결 비용 절감

#### 외부 라이브러리 문제
- 문제: 레거시 컨테이너화 중 라이선스 문제로 서비스 장애
- 해결: Binary Ninja로 분석 -> 즉시 원인 파악, 담당사에 요청 후 해결

#### 정리
- **정확한 병목 지점 파악**이 중요: 추측이 아닌 프로파일링 기반 분석
- **도구 활용 능력**: JVM, 네트워크, 커널, 네이티브 등 레이어별 도구 숙련 필요
- **자동화 필요성**: 반복되는 이슈 분석은 배포 프로세스/관측에 자동화 적용
- **환경 의존성 고려**: 커널 버전, GC 옵션, 라이브러리 동작 방식이 성능에 직접 영향

---

### 토스 실시간 시세 데이터 안전하고 빠르게 처리하기
- 한국거래소에서 전달되는 시세 데이터(체결가, 호가, 공매도 현황 등)를 **실시간 처리**해야 함
- 장 열린 상태에서 장애 발생 시 -> 사용자 단에 잘못된 시세 노출 -> 투자 혼란 + 고객센터 불만 폭주
- 처리 부분에서 장애 시 **데이터 유실/오염** 문제 발생 -> 단순 복구로 해결 불가
- 피크타임(오전 9시) 기준 **초당 수천 건 이상** 데이터 유입

### 해결 방법

### 이중화 및 Failover 구조
- 처리부 + Redis를 **A/B 그룹**으로 이중화
- 장애 시, **정상 그룹으로 빠른 전환** -> 오염 데이터 복구보다 **정상 데이터 활용** 우선
- 배포 시 A/B 그룹 번갈아 적용 -> **Blue-Green 배포 + 빠른 롤백** 지원
- 각 그룹 내 리더 선출(ZooKeeper) -> **중복 데이터 방지**

### 메시지 브로커 도입
- Producer, Consumer 직접 연결 구조 -> **Consumer 개수 증가 시 성능 저하**
- **Redis Pub/Sub** 도입
  - Kafka: 15ms, Redis Pub/Sub: 3ms (Kafka 보다 빠름)
- Redis Pub/Sub 특성: 구독자 없으면 메시지 버림 -> **지연 최소화** (실시간성 극대화, 유실 감수)

### Consumer 성능 최적화
- 문제: 처리부에서 비즈니스 로직(Blocking I/O)으로 지연 발생
- 해결
  - 비즈니스 로직을 **별도 스레드/이벤트 루프 그룹**으로 분리
  - 이벤트 루프 기반 구조로 **순서 보장 + 동기화 불필요**
  - Redis 채널을 이벤트 루프 개수만큼 분할 -> 객체 변환 생략, CPU 부하 절감

### 멀티스레딩/이벤트 루프 튜닝
- 이벤트 루프 개수 조정 -> 과도하면 **Context Switching 오버헤드**, 부족하면 **Backpressure 발생**
- 성능 테스트로 적정 개수 탐색
- 최적화 기법
  - Redis 저장 비동기 처리 (`ReactiveRedisTemplate`)
  - **로컬 캐시 조회**로 Redis Blocking I/O 최소화
  - 배치/DB 등 무거운 작업은 **별도 이벤트 루프 그룹**으로 분리

### 성과
- 22,000 TPS 환경에서 **1ms 이하 처리 지연** 달성
- 안정적 실시간 시세 제공 -> 피크 타임에도 데이터 누락/지연 최소화
- 장애 발생 시 빠른 그룹 전환으로 **무중단 서비스** 가능

### 정리
- 서비스에 따라 **장애 복구보다 빠른 Failover**가 중요할 수 있음
- 실시간 시스템은 **데이터 일관성보다 지연 최소화**를 우선해야 하는 경우 존재
- 멀티스레딩, 이벤트 루프, 메시지 브로커 선택 등 **시스템 설계 결정이 곧 성능**을 좌우

---

## 3. 느낀 점 (Insights)
- SNS 상에서 개발자 분들이 장애 파악 및 대응 관련 내용으로 간단한 토론하는 것을 구경하다가 갑자기 궁금해져서 기술 블로그에서 이런 부분을 찾아서 보고, 또 혼자 나름 고민해보았다.
- 기술 블로그 볼 때마다 느끼는 점은.. 내가 100프로 이해하지는 못해도 이런 방법이 있구나~ 라는 인사이트를 얻는 것만으로도 큰 도움이 되는 것 같다! 특히 모니터링 툴은 학부생 수준에서 사용할 일이 많이 없기 때문에(ㅜㅜ) 사실 거의 다 처음 듣는 툴이지만 그래도 공부하면서 재밌었다~
- 장애 모니터링이 중요하다는 것은 알고 있었지만 이를 어떻게 파악하고 해결하는 지에 깊게 생각해본 적은 이번에 처음인 것 같다!ㅜㅠ 열심히 공부하자~

---

## 4. 참고/추가 자료 (References)
- [토스 기술 블로그 - 우리는 어떻게 해외주식 서비스 안정화를 이뤘는가](https://toss.tech/article/overseas-securities-server)
- [토스ㅣSLASH 23 - 프로파일러로 시스템 성능 향상시키기](https://www.youtube.com/watch?v=tZjjqhnwtYY)
- [토스ㅣSLASH 23 - 실시간 시세 데이터 안전하고 빠르게 처리하기](https://www.youtube.com/watch?v=SF7eqlL0mjw)

---

## 5. 내일/다음에 볼 것 (Next-Steps)
- 성능 병목 지점을 어떻게 파악하고 해결할 것인가... 