# 📚 Cache

---

## 1. 주제/키워드 
- 캐시와 redis에 대해 알아보자!! (つ✧.✧)つ-✧҉*

---

## 2. 핵심 요약 (Summary)

### Cache
- 값 비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, **다음 요청이 빨리 처리**될 수 있도록 하는 저장소
- 애플리케이션 성능은 DB를 얼마나 자주 호출하는가에 많이 영향을 받음 -> 캐시를 통해 성능 향상
- **Cache Tier**(캐시 계층)
  - 데이터 임시 저장소(DB보다 훨씬 빠름)
  - 성능 개선, DB 부하 감소, 캐시 계층 규모를 독립적으로 확장 가능
- **Read-Through Caching Strategy** (캐시 우선 읽기 전략)
  - 웹 서버가 클라이언트 요청 받음
  - 먼저 캐시에 응답이 저장되어있는지 확인
  - 만약 있다면, 해당 데이터를 클라이언트에게 반환
  - 없다면 DB에서 읽어서 **캐시에 저장** 후 클라이언트에게 반환
- 캐시 서버에서 제공하는 API로 이용
- **Cache Hit**
  - 찾고 싶은 데이터가 캐시에 있음
- **Cache Miss**
  - 찾고 싶은 데이터가 캐시에 없음
- **Cache Hit Ratio** (캐시 적중률)
  - 얼마나 자주 캐시 히트가 발생하는지 비율
  - `Cache Hit Rate = 캐시 히트 수 / 전체 요청 수`
  - 보통 80~90% 이상이면 캐시가 잘 동작
- **Cache Invalidation** (캐시 무효화)
  - DB 원본 데이터가 바뀌었을 때, 캐시된 데이터를 더 이상 신뢰할 수 없게 만드는 작업
  - **TTL**: 일정 시간 지나면 자동 만료
  - **삭제**: DB 갱신 시 캐시 삭제
  - **갱신**: DB 갱신 시 동시에 캐시도 갱신

---

### Cache Strategy(캐시 전략)
- 그럼 도대체 언제 캐시해야할까?
- **Cache Aside** (Lazy Loading)
  - 요청이 있을 때만 캐시하는 방법
    ```text
    클라이언트가 데이터를 요청함
    캐시에 없음 -> DB 조회
    DB에서 값을 가져와 캐시에 저장
    다음 요청부터 캐시에서 조회
    ```
  - 장점
    - 불필요한 데이터는 캐시에 저장하지 않음
    - 캐시 미스 시 DB fallback(캐시에 없을 때 DB에서 조회)가능
  - 단점
    - 첫 조회가 느림(DB에서 값 읽어와야함)
    - write(update, insert, delete)시 **직접 캐시 갱신 혹은 무효화해야함**
  - Spring+redis 조합에서 많이 사용
  - **조회가 많은 데이터**에서 자주 사용(ex. 상품 정보)
- **Write Through**
  - write(update, insert, delete)와 동시에 캐시에 반영
    ```text
    클라이언트가 데이터를 업데이트 요청함
    캐시에 반영
    동시에 DB도 갱신
    ```
  - 캐시와 DB 간 일관성 높지만, 성능이 낮아짐
  - 주로 일관성이 매우 중요한 데이터에 사용
- **Write Back** (Write Behind)
  - 캐시에 먼저 쓰고, 일괄 처리(batch) 또는 TTL/Trigger에 따라 DB에 저장
    ```text
    캐시에만 저장
    주기적으로 또는 비동기로 DB 반영
    ```
  - 장점
    - 쓰기 성능 향상(속도 빠름), write 병목 최소화
  - 단점
    - 캐시 장애 발생 시 DB 반영 전 데이터 유실 위험
    - 구현 복잡 (**비동기 처리**, 장애 복구 고려 필요)
  - 로그/분석/통계성 비필수 데이터에 사용
  - 주로 Kafka, 비동기 큐와 함께 사용
  - ex. 조회수 증가 구현 시 먼저 redis에 저장하고 5분마다 worker가 redis 값을 읽어 DB에 저장

---

### Cache Eviction(캐시 축출)
- 캐시은 메모리 용량이 정해져있기 때문에, 덜 중요한 데이터는 제거해야함
- **LRU** (Least Recently Used)
  - 가장 오래 사용되지 않은 데이터 삭제
  - 대부분의 캐시 라이브러리(ex. Redis, Caffeine)가 기본값으로 사용
  - 제일 직관적인 방법
  - 캐시 사용 히스토리를 linked list로 관리
- **LFU** (Least Frequently Used)
  - 가장 적게 사용한 데이터 삭제
  - 자주 쓰이는 항목은 오래 살아남음
  - **특정 key가 핫하게** 쓰이는 경우 적합(인기 키워드, 조회수 순위 등)
  - 구현 복잡도는 LRU보다 높음
- **FIFO** (First In First Out)
  - 가장 먼저 들어온 데이터부터 삭제
  - 단순하지만 비효율적
- **Random**
  - 랜덤하게 삭제
  - 캐시 부하가 심할 때 사용
  - 빠르지만 정확성/효율은 떨어짐 -> 데이터 중요도 낮을 때 사용


---

### 캐시 사용 시 주의할 점
- 캐시는 어떤 상황에 사용할까?
  - 데이터 update는 자주 일어나지 않지만, **read가 자주** 일어나는 경우
- 어떤 데이터를 캐시에 저장할까?
  - 캐시는 데이터를 휘발성 메모리에 저장
  - 따라서 중요하고, 오래 보관해야하는 데이터는 캐시가 아닌 지속적 저장소(persistent data store)에 저장해야함
- 캐시에 보관된 데이터는 **어떻게 만료**(expire)해야할까?
  - 만료 정책이 없으면 데이터가 캐시에 계속 남음
  - 만료 기간이 너무 짧으면 DB값을 너무 자주 읽음 -> 캐시 사용 이유가 사라짐
  - 만료 기간이 너무 길면 원본 데이터 값과 차이가 날 가능성이 높아짐 -> 데이터 일관성X
  - 따라서 적절한 만료 기간을 설정해야함
- **일관성**(consistency)는 어떻게 유지할까?
  - 일관성: 데이터 저장소 원본과 캐시 내 사본이 같은 지 여부
  - 시스템을 계속 확장해 나가는 경우, 일관성 유지는 점점 어려워짐
  - 저장소 원본 갱신 연산과 캐시 갱신 연산을 단일 트랜잭션으로 처리하면 일관성 유지 가능
- **장애**에 어떻게 대처해야할까?
  - 캐시 서버가 1개인 경우, **단일 장애 지점**(Single Point of Failure, SPOF)이 됨
  - 단일 장애 지점: 해당 장소의 **장애가 전체 시스템의 동작을 중단** 시킬 수 있는 특정 지점
  - 따라서 SPOF를 피하기 위해 **캐시 서버를 분산**시켜야함
- **캐시 메모리**는 얼마나 크게 잡을까?
  - 메모리가 너무 작으면 데이터가 자주 캐시에서 밀려남(eviction) -> 성능 저하
  - 캐시 메모리를 과할당(overprovision) -> 캐시 보관 데이터가 갑자기 증가할 때 문제 방지

---

### 캐시를 사용해도 DB 부하가 발생하는 상황

### Cache Stampede (캐시 쇄도)
- <img src="image/cache/1.png" alt="설명" width="400"/>
- 동시에 여러 캐시가 만료되어 캐시 미스가 많이 발생하는 경우
- 캐시가 특정 시간(매일 자정 등)에 만료하게 하는 경우 자주 발생
- 해결책: **Jitter**(지터)
  - 지터: 전자 신호를 읽는 과정에서 발생하는 **짧은 지연 시간**
  - 따라서 만료 시간에 지터와 같이 0~10초 사이 무작위 지연 시간을 더하면 DB 부담이 10초에 나누어 분산됨(**DB 부하 균등 분산**)
  - 지터가 길어지면 사용자가 그만큼 오래된 데이터를 보는 것이므로, 적절한 시간을 설정해야함

### Cache Penetration (캐시 관통)
- <img src="image/cache/2.png" alt="설명" width="400"/>
- 캐시에서 `null`이면 cache miss라고 판단하여 DB에서 조회하여 값을 채움
- 하지만 만약, DB 값 자체가 `null`이라면?
- 캐시에 값을 채우지 않는다면, DB 조회가 반복됨 -> 성능 저하
- 따라서 **DB 반환 값이 없다**라는 사실을 캐시에 저장해야함
- 해결책: **Null Object Pattern**
    - `bloom filter` 방식의 문제점
      - Bloom filter: 어떤 값이 집합에 존재하는지 아닌지를 빠르게 판단하는 자료구조
      - Bloom filter 정합성 문제
        - 존재한다고 했지만 거짓일 확률 존재(false positive)
        - 삭제 불가 문제
      - 이로 인해 존재하지 않는 값을 존재한다고 하여 cache miss를 유발할 수 있음
    - 따라서 Null Object Pattern을 사용
      - 객체 타입: null 대신 값이 없음을 표현할 객체를 선언해서 사용
      - 원시 타입: 특정 값을 지정(ex. 양수 값만 가능할 때 -1 반환)

### 캐시 시스템 장애
- <img src="image/cache/3.png" alt="설명" width="400"/>
- 트래픽이 적으면 캐시 시스템에 문제가 생겨도 DB에 트래픽을 보내면 됨
- 하지만 트래픽이 많은 경우, DB에 과부하가 걸릴 확률이 높음
- 해결책: Failover(대체 작동)
  - 반드시 작동해야하는 핵심 기능을 제외하고 부가 기능은 작동 중단
  - 부가 기능 관련해서는 사용자에게 UI 등으로 양해 부탁

### 핫키(Hotkey) 만료
- <img src="image/cache/4.png" alt="설명" width="400"/>
- 핫키: 요청이 집중되는 키
- 핫키가 만료되면 여러 요청이 불필요하게 중복될 가능성 존재
- 따라서 핫키는 만료시키지 않거나, 백그라운드에서 주기적으로 새로운 값을 적용해서 만료되지 않도록 하는게 좋음
- 하지만 핫키가 주기적으로 바뀌는 환경이라면?
- 기존의 핫키가 더이상 핫키가 아니기 때문에 불필요한 공간 낭비
- 해결책: 분산 락(Distributed Lock)
  - 분산 락: 여러 서버나 프로세스가 동시에 하나의 자원에 접근할 때,
**오직 하나만 접근할 수 있도록 제어하는 락**(lock)
  - 공간 낭비 없이 불필요한 데이터베이스 중복 조회를 방지
  - cache miss 때 락을 설정하고, 캐싱하고 락을 해제 -> 한 번의 쓰기 작업만 허용
  - redis의 경우, **redlock** 알고리즘을 사용
    - redis의 싱글 스레드 특징을 활용
    - 여러 redis 노드(보통 5개)에 락을 동시에 요청해서,다수(ex. 3개 이상)에게 락을 얻은 경우만 성공으로 간주

---

### **Strong consistency**가 필요한 경우(민감 데이터)
- Strong consistency: DB commit 시 다음 요청에서 해당 사항이 무조건! 반영되어 정확히 응답해야함
  - 만약, Replication된 DB를 사용하여 부하를 줄인다면, Replication Delay(복제 지연)이 발생할 가능성이 있음
    - 복제 지연: 주 DB(Primary)와 보조 DB(Replica) 간의 데이터 동기화가 지연되는 현상
  - 따라서 **Redis Cache를 통해 Strong consistency 유지**
- **DB commit 이후 캐시 만료해서 데이터 일관성 지킴**(`@EntityListener`, `@TransactionalEventListener`)
  - 만약 DB commit 이전에 캐시 만료가 된다면, 다른 요청에서 commit 전 데이터를 다시 캐시에 적재하는 문제가 발생할 수 있음
  - A 스레드가 DB commit 요청해서 캐시 만료했는데, B 스레드가 해당 데이터 요청하면 cache miss로 데이터를 다시 캐시에 올림. 근데 이 데이터는 DB commit 되지 않은 이전의 데이터임. 캐시에 올라간 잘못된 데이터를 다른 C 스레드가 요청하면 cache hit로 해당 데이터를 사용해버림 -> 데이터 일관성 깨짐!
- 근데 여기서 또 문제가 있음!
- 만약 **캐시 만료에 실패**하면? 이전 데이터가 계속 캐시에 남아있음!
  - 왜냐하면, DB commit에는 성공한 상태이기 때문에, rollback이 작동하지 않음
  - 따라서 ``Circuit Breaker``를 사용하여 cache evict 실패 시에 circuit를 **force open**하여 cache 요청이 들어왔을 때,circuit이 open 되어있다면, **모든 트래픽은 바로 DB를 조회**하도록 하여, 잘못된 캐시가 응답되지 않도록 방어
  - 이 방법은 DB에 부하를 가중시키기 때문에 데이터 일관성이 중요한 시스템에서 사용
- 근데 여기서 또 문제가 생김! ~~(취업하면진짜테스트지옥이겠구나)~~
- 커밋 후 캐시 만료하는 그 0.03초 사이에 Kafka Event를 Consume한 곳에서 잘못된 캐시를 조회하는 문제
  - Kafka Event를 Cache Evict 처리 이후에 발행하도록 변경

---

### Redis (Remote Dictionary Server)
- 인메모리(In-Memory) 기반 데이터 저장소
- Key-Value 기반 구조
- 매우 **빠른 속도**를 제공 -> 주로 캐시, 세션 관리, 메시지 브로커, 순위표 등에 활용
- 데이터 구조
  - String: 가장 기본적인 타입 (카운터, 세션 값 저장)
  - List: 메시지 큐처럼 활용 가능
  - Hash: 객체(필드-값) 저장, 유저 정보 저장에 유용
  - Set: 중복 없는 집합 (태그, 좋아요 유저 목록)
  - Sorted Set(ZSet): 점수 기반 정렬된 집합 (랭킹, 순위표)
  - Bitmap/HyperLogLog: 대규모 데이터 집계 최적화
- **Persistence** (영속성)
  - 레디스는 기본적으로 메모리 기반이라 **장애가 나면 데이터 유실 위험**이 있음!
  - 이를 방지하기 위해 Persistence(지속성 보장) 기능을 제공
  - RDB (Redis Database Snapshot)
    - **일정 주기**마다 메모리 스냅샷 찍어서 디스크에 저장
    - 장점
      - **복구 빠름** -> 전체 데이터를 한 번에 로드
      - **파일 용량이 작음** -> 압축된 단일 파일(dump.rdb)
      - 성능 영향이 상대적으로 적음 (주기적으로만 발생)
    - 단점
      - 마지막 스냅샷 이후 데이터는 복구 불가 -> **데이터 유실 발생 가능**
      - 따라서 스냅샷 주기가 길면 유실 범위가 많음
  - AOF (Append Only File)
    - **모든 write** 명령 로그 기록
    - 장점
      - **데이터 유실 최소화** -> everysec 설정 시 최대 1초까지만 유실
      - 사람이 읽을 수 있는 로그라 디버깅 용이
    - 단점
      - 파일 크기 큼 (RDB 대비 수십 배까지 가능)
      - 지속적인 디스크 I/O 발생 -> 성능 안좋음
      - 장기 실행 시 파일 용량 커져서 rewrite(재압축) 필요
  - 둘을 혼합하여 사용 가능
- Redis Scale Out 방식
  - **Replication**
    - 복제 이용 확장 방식
    - Primary(Master) <- (비동기 복제) - Replica(Slave)
  - **Cluster**
    - 샤딩 이용 확장 방식
  - 더 자세한 내용은 DB scale out 파트에서~
- **싱글 스레드**
  - Redis는 싱글 스레드이지만, I/O 멀티플렉싱(Event Loop) 기반으로 처리 -> 동시성 성능 높음
- 여기서 잠깐!
- I/O 멀티플렉싱이란?
  - 보통 서버는 소켓 요청(네트워크 입출력)을 처리할 때, blocking 방식이면 요청 하나 끝날 때까지 다음 요청을 못 봄
  - Redis는 epoll, select, kqueue 같은 **OS 커널 기능을 활용**해서
    - 여러 클라이언트 소켓을 한 번에 감시
    - 읽기/쓰기 이벤트가 준비된 소켓만 처리
  - 즉, 준비된 일만 빠르게 처리하고, 준비 안 된 건 기다림

--- 

### Redis가 빠른 이유
- 갑자기 궁금해짐... Redis는 싱글 스레드라면서 왜! 빠른가~
- **락(lock) 없음**
  - 멀티 스레드 DB(MongoDB, MySQL)에서는 Lock/Unlock 오버헤드 발생
  - Redis는 싱글 스레드라서 락 필요 없음
- **메모리 기반**
  - 디스크가 아니라 RAM에서만 작업 -> 속도 자체가 수십 배 이상 빠름
- **작은 명령 단위**
  - GET, SET, INCR 같은 O(1) 수준 연산이 대부분이라 CPU 계산 부담이 적음
- **Event Loop**
  - 수천 개 연결을 동시에 처리 가능 (한 번에 조금씩 나눠 처리)
- 여기서 의문점... 음? 내가 알기로 레디스에서 락을 지원하는데..?
- 하나의 DB, 싱글 스레드에서는 락을 신경 쓸 필요가 거의 없지만, **분산 환경**에서는 분산락(distributed lock) 개념이 필요해짐!

--- 

### Redis Lock
- 기본 락 (SETNX 활용)
  - `SETNX key value` -> key가 없으면 세팅
  - 만약 다른 프로세스가 이미 key를 잡았다면 실패 -> 대기 or 재시도
  - 단점
    - 역시나 .. 데드락(deadlock)
    - TTL(만료 시간) 안 걸면 무한 lock

---

### Redlock (분산 락)
- Redis 공식 문서에서 제안한 분산 환경에서 안전한 락 구현 방식
- 문제 상황
  - Redis 인스턴스가 여러 개(클러스터/샤딩 환경)일 때 단일 노드에만 락을 걸면 안전하지 않음
  - 예를 들어보면
  - 클라이언트 A가 Primary에 락 획득
  - 단일 Primary에만 락을 건 경우 이 키는 Primary에 저장되고 Replica에도 비동기 복제됨. 근데 **복제 지연**(Replication Lag)으로 인해 Replica는 Primary보다 아~~주 조금 늦게 데이터 반영
  - 근데 만약 락 키가 아직 Replica에 복제되기 전에 Primary가 죽으면? 허걱!!
  - Replica(A)는 **락이 없는 상태라고 생각**함
  - 이때 Primary가 죽었기 때문에, Failover 발생!
  - 따라서 Replica(A)를 새로운 Primary로 승격
  - 이제 다른 클라이언트(B)가 같은 자원에 락을 걸려고 시도하면?
  - Replica(A)에는 락이 안 들어있으니 B도 락 획득 성공
  - 결과적으로 A, B 둘 다 같은 자원에 락을 가진 상태 -> 동시 접근 발생!
- **Redlock 원리**
  - 여러 Redis 노드(보통 5개)에 **같은 key를 세팅** 시도 (`SET resource_name my_random_value NX PX 30000`)
    - NX: Not eXists (아직 존재하지 않을 때만 세팅 -> 락 중복 방지)
    - PX: TTL 설정
  - 다수(예: 5개 중 3개 이상)에서 성공하면 락 획득 성공으로 간주
  - 클라이언트가 작업 후 -> 동일한 random value로 락 해제 (자기 락만 해제하도록)
  - TTL이 지나면 자동 해제 (데드락 방지)
  - 장점
    - 단일 노드 장애에도 안전
    - 락 유실/재획득 문제를 줄임
  - 단점
    - 네트워크 지연, Redis 장애 타이밍에 따라 여전히 완벽한 분산락 보장은 어려움
    - 따라서 강한 분산락이 필요한 경우에는 Zookeeper, Etcd 등을 사용(추후 공부해보자!)
- 그럼 언제 쓸까용
- Redis 분산락 유용한 경우
  - 예약/결제 같은 **중복 허용 불가 로직**
    - 쇼핑몰 재고 차감 (동일 상품 다중 주문 방지)
    - 쿠폰 발급(중복 발급 방지)
- Redis 락 쓰지 말아야 할 경우
  - 데이터 강한 일관성이 필수인 금융거래(이체 등) -> 안전하게 DB 트랜잭션 or Zookeeper/Etcd 기반 락 사용

---

### Redis 원자성 보장
- Redis는 싱글 스레드 이벤트 루프 기반으로 동작 -> **한 번에 하나의 명령**만 처리!!
- 따라서 단일 명령(Command)은 기본적으로 원자성(Atomicity) 보장
- 하지만 **여러 명령을 묶어서 실행하면 원자성이 깨질 수 있음**
- 해결 방법
  - MULTI/EXEC (Transaction)
    - 여러 명령을 큐잉 후 한번에 실행
    - 근데 Redis 트랜잭션은 롤백이 없음 -> DB의 트랜잭션처럼 ALL OR NOTHING은 아님 (오류 나면 그 명령만 실패)
  - Lua Script
    - 레디스 서버 내부에서 스크립트 실행 -> 외부에서 보기에 하나의 명령처럼 동작
  - Bookdam에서 ISBN 중복 체크 같은 경우, Lua Script로도 race condition 방지 가능
    - ISBN 중복 체크 로직 설계
      - 새 책 ISBN 들어옴 -> Redis에서 `EXISTS isbn:123` 확인
        - 있으면 -> 이미 DB에 있다고 판단하고 skip
        - 없으면 -> DB에 insert 시도 + Redis에 `SET isbn:123 true` 저장
      - 근데 만약 동시에 두 요청이 들어오면 둘 다 없다고 보고 Insert 시도 -> 중복 발생 가능!
      - Lua Script로 묶으면 존재 확인 + 세팅을 하나의 작업으로 처리 가능!
      - 근데 사실 캐시에 없어도 디비에 존재할 가능성 존재
        - 따라서 캐시는 1차 필터 느낌이고, ISBN을 유니크 인덱스 처리 + 트랜잭션 커밋 후 캐시 반영/무효화 결정(중복이면 캐시에 추가해서 더 이상의 cache miss 줄이기) + 주기적으로 데이터 오염값 처리 이런 식으로 설계해야 안전할듯!

---

### Redis 장애 발생 시 대응 방법
- **Failover** (자동 전환)
  - Redis Sentinel이 Primary에 장애 발생을 감지하면, Replica를 새 Primary로 승격
  - 단점: 전환 과정에서 수 초간 write 불가 -> 잠깐의 데이터 유실 가능
- **Fallback** (**DB 직접 조회 허용**)
  - Redis 캐시에 저장된 책 정보가 만료되었는데 Redis가 죽은 경우, 바로 MySQL로 fallback
  - 기능은 유지 가능하지만 -> DB 트래픽 급증 -> 오히려 DB가 죽을 수도 있음..
  - 그래서 fallback 시에는 **DB 부하 분산 전략** (읽기 전용 Replica DB, CQRS 구조 등)도 필요 (이 부분도 더 공부합시다...!)
- **Graceful Degradation** (점진적 기능 축소)
  - 만약, 어떤 서비스에서 좋아요 수, 댓글 수는 Redis에 저장되어 있음
  - Redis 장애 발생 시 -> 다른 내용들은 DB에서 가져와 보여주고, 좋아요 수는 잠시 표시 불가 처리
  - **핵심 기능은 유지하면서, 부가 기능만 포기** -> 사용자가 불편을 겪지만 서비스 중단은 방지
- **Circuit Breaker**
  - Redis 응답이 계속 실패하면 Circuit이 Open -> Redis 호출 중단, 바로 DB 조회
  - 일정 시간 뒤 Half-Open 상태에서 Redis 복구 확인 후 -> 다시 닫고 Redis 사용
  - 문제가 발생한 Redis 계속 접근하는 cache miss를 막고, 빠르게 DB fallback
  - 하지만 마찬가지로 Redis가 장시간 죽어 있으면 결국 DB가 버티기 힘들 수 있음

--- 

### Redis를 DB처럼 쓸 때 문제
- 갑자기 궁금해서... 왜 Redis를 MySQL, MongoDB 처럼 쓰지 않는 걸까?
- 고민해보면 쉽긴 한데... 생각나는대로 정리해보자!
- **데이터 유실 위험** (특히 Write-back 시)
  - 게시글 “조회수”를 Redis에만 저장하고 5분마다 DB로 반영한다고 하자!
  - 반영 직전 Redis 장애 -> 5분간의 조회수 기록 통째로 유실
  - 그래서 Write-back은 필수 데이터엔 쓰면 안 되고, 조회수, 로그 같은 손실 허용 데이터에만 사용해야함
- **데이터 용량 한계** (수백 GB 이상 운영 어려움)
  - Redis는 메모리 기반 -> RAM 가격 비쌈ㅜㅜ
- **복잡 쿼리 미지원**
  - Redis는 단일 key-value 조회엔 빠름, 하지만 JOIN이나 WHERE 조건 검색 불가

---

## 3. 참고/추가 자료 (References)
- 가상 면접 사례로 배우는 대규모 시스템 설계 기초
- [Redis 공식 문서](https://redis.io/docs/latest/)
- 토스 기술 블로그
  - [캐시를 적용하기 까지의 험난한 길 (TPS 1만 안정적으로 서비스하기)](https://toss.tech/article/34481)
  - [캐시 문제 해결 가이드 - DB 과부하 방지 실전 팁](https://toss.tech/article/cache-traffic-tip)
- 대학 때 들었던 강의

---

## 4. 내일/다음에 볼 것 (Next Steps)
- redis 공부 + 적용!
- 고민하는 내용 계속 추가하다보니까 중복되는 내용이 많아지는군...
